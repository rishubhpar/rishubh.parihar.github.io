<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rishubh Parihar</title>
  
  <meta name="author" content="Rishubh Parihar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦¥</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rishubh Parihar</name>
              </p>
              <p style="text-align: justify;"> 
              <font size="3"> I am a third year Ph.D. student at <a href="https://iisc.ac.in/"> Indian Insitute of Science, Bangalore </a> and associated with <a href="https://val.cds.iisc.ac.in/"> Video Analytics Lab </a>. I am advised by <a href="http://cds.iisc.ac.in/faculty/venky/">Prof. Venkatesh Babu</a> from Department of Computational and Data Sciences.
              Previously, I worked at <a ref="https://sharechat.com/">ShareChat</a> where I developed and deployed large scale machine learning algorithms for content moderation for social media platforms ShareChat and Moj. Even before that, I worked on developing computer vision solutions for smartphones at <a href="https://research.samsung.com/sri-b">Samsung Research Bangalore</a>. 
              I graduated with Bachelor of Technology in Mathematics and Computing in 2018 from <a href="https://home.iitd.ac.in/">Indian Insitute of Technology Delhi</a>.</font>
              </p>
              <p style="text-align: justify;"> 
              <font size="3">
                My research interests are <strong>Image and Video manipulation with deep generative models</strong>. Specifically, my research focus on leveraging rich priors from deep generative models for downstream image editing tasks. 
              </font>
              </p>
              <p style="text-align:center">
                <a href="mailto:rishubhp@iisc.ac.in">Email</a> &nbsp/&nbsp
                <a href="data/rishubh_parihar_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=RaRoJFYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rishubh-parihar?originalSubdomain=in">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/rishubhpar/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/rishubh_parihar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/rishubh_parihar.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><font size="6">Research</font></heading>
              <p>
                <font size="3">Below is an representative list of my research works. Feel free to contact if you find this interesting.</font>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        
          <!-- Explore diverse attributes --> 
          <tr onmouseout="attributediff_stop()" onmouseover="attributediff_start()">
            <td style="padding:0px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='attributediff_image'>
                  <img src='images/attributediff_after.gif' width="300"></div>
                  <img src='images/attributediff_before.gif' width="300">
              </div>
              <script type="text/javascript">
                function strata_start() {
                  document.getElementById('attributediff_image').style.opacity = "1";
                }

                function strata_stop() {
                  document.getElementById('attributediff_image').style.opacity = "0";
                }
                strata_stop()
              </script>
            </td>

            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2311.16052.pdf">
                <papertitle><font size="5">Exploring Attribute Variations in Style-based GANs using Diffusion Models</font></papertitle>
              </a>
              <br> 
              <font size="3">
              Rishubh Parihar,
              Prasanna Balaji,
              Raghav Magazine,
              Sarthak Vora,
              Tejan Karmali,
              Varun Jampani,
              R. Venkatesh Babu
              </font>
              <br>
              <strong>NeurIPS Workshop on Diffusion Models, 2023 </strong> 
	      <br>
              <a href="https://arxiv.org/pdf/2311.16052.pdf">arXiv</a> 
              <br>
              <p></p> 
              <p style="text-align: justify;"> 
                Existing attribute editing methods treat semantic attributes as binary, resulting in a single edit per attribute.  However, attributes such
                 as eyeglasses, smiles, or hairstyles exhibit a vast range of diversity. In this work, we formulate the task of diverse attribute editing by 
                 modeling the multidimensional nature of attribute edits.  We capitalize on disentangled latent spaces of pretrained GANs and train a Denoising Diffusion 
                 Probabilistic Model (DDPM) to learn the latent distribution for diverse edits. This leads to latent subspaces that enable diverse attribute editing. 
                 Applying diffusion in the highly compressed latent space allows us to model rich distributions of edits within limited computational resources
              </p>
            </td>
          </tr>		

          <!-- StrataNerF paper -->
          <tr onmouseout="strata_stop()" onmouseover="strata_start()">
            <td style="padding:15px;width:30%;vertical-align:center">
              <div class="one">
                <div class="two" id='stratan_image'>
                  <img src='images/stratan_after.gif' width="250"></div>
                  <img src='images/stratan_before.gif' width="250">
              </div>
              <script type="text/javascript">
                function strata_start() {
                  document.getElementById('stratan_image').style.opacity = "1";
                }

                function strata_stop() {
                  document.getElementById('stratan_image').style.opacity = "0";
                }
                strata_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://ankitatiisc.github.io/Strata-NeRF/">
                <papertitle><font size="5">Strata-NeRF: Neural Radiance Fields for Stratified Scenes</font></papertitle>
              </a>
              <br>
              <font size="3">
              Ankit Dhiman,
              R Srinath,
              Harsh Rangwani,
              Rishubh Parihar,
              Lokesh R Boregowda,
              Srinath Sridhar,
              R. Venkatesh Babu
              </font>
              <br>
              <Strong>ICCV, 2023</Strong>
	      <br>
              <a href="https://ankitatiisc.github.io/Strata-NeRF/">project page</a>
              /
              <a href="https://arxiv.org/abs/2308.10337">arXiv</a>
              /
              <a href="https://github.com/ankitatiisc/Strata-NeRF">code</a> 
              <br>
              <p></p> 
              <p style="text-align: justify;"> 
              Existing NeRF approaches concentrate on modelling a single object or a single level of a scene. However, in the real world, we may capture a 
              scene at multiple levels, resulting in a layered capture. For example, tourists usually capture a monumentâ€™s exterior structure before capturing the inner structure.  
              We propose Strata-NeRF, a single neural radiance field that implicitly captures a scene with multiple levels. Strata-NeRF achieves this by conditioning the 
              NeRFs on Vector Quantized (VQ) latent representations which allow sudden changes in scene structure. 
              </p>
            </td>
          </tr>		


	
          <!-- Motion Style paper -->
          <tr onmouseout="flame_stop()" onmouseover="flame_start()">
            <td style="padding:0px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='motion_image'>
                  <img src='images/motion_style_after.gif' width="300"></div>
                <img src='images/motion_style_before.gif' width="300">  
              </div>
              <script type="text/javascript">
                function motion_start() {
                  document.getElementById('motion_image').style.opacity = "1";
                }

                function motion_stop() {
                  document.getElementById('motion_image').style.opacity = "0";
                }
                motion_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://rishubhpar.github.io/motionstyle/">
                <papertitle><font size="5">We never go out of Style: Motion Disentanglement by Subspace Decomposition of Latent Space</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Raghav Magazine,
              Piyush Tiwari,
              R. Venkatesh Babu
              </font>
              <br>
              <Strong>CVPRW, AI for Content Creation Workshop, 2023</Strong> 
	      <br>
              <a href="https://rishubhpar.github.io/motionstyle/">project page</a>
              /
              <a href="https://arxiv.org/abs/2306.00559">arXiv</a>
              /
              <a href="https://youtu.be/ngqXK5VJGzo">video</a>
              <br>
              <p></p> 
              <p style="text-align: justify;"> 
               In this work, we propose a novel method to decompose motion in videos by using a pretrained image GAN model. We discover disentangled motion subspaces in the latent space of widely used style-based GAN models that
	       are semantically meaningful and control a single explainable motion component. The proposed method uses only a few (â‰ˆ10) ground truth video sequences to obtain such subspaces. 
              </p>
            </td>
          </tr>		


          <!-- FLAME paper -->
          <tr onmouseout="flame_stop()" onmouseover="flame_start()">
            <td style="padding:15px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flame_image'>
                  <img src='images/flame_after.gif' width="250"></div>
                <img src='images/flame_before.gif' width="250">
              </div>
              <script type="text/javascript">
                function flame_start() {
                  document.getElementById('flame_image').style.opacity = "1";
                }

                function flame_stop() {
                  document.getElementById('flame_image').style.opacity = "0";
                }
                flame_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://sites.google.com/view/flamelatentediting/">
                <papertitle><font size="5">Everything is in the Latent Space: Attribute Style Editing and Attribute Style Manipulation
                by StyleGAN Latent Space Exploration</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Ankit Dhiman,
              Tejan Karmali,
              R. Venkatesh Babu
              </font>
              <br>
              <Strong>ACMMM, 2022</Strong>
	      <br>
              <a href="https://sites.google.com/view/flamelatentediting/">project page</a>
              /
              <a href="https://arxiv.org/abs/2207.09855">arXiv</a>
              /
              <a href="https://drive.google.com/file/d/1LgKowoYnaJ5sX5TAI7heGOLhGkTbZ5qS/view">video</a>
              <br>
              <p></p> 
              <p style="text-align: justify;"> 
              In this work we proposed a Few-shot Latent based Attribute Manipulation and Editing (FLAME) method, a simple yet effective framework to perform highly controlled image editing by latent space manipulation.
              FLAME can generate highly realistic attribute edits and enables us to generate diverse attribute styles such as hair-styles, trained with only a few set of image pairs. 
              </p>
            </td>
          </tr>		

      
          <!-- HSR Paper --> 
          <tr onmouseout="hsr_stop()" onmouseover="hsr_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hsr_image'>
                  <img src='images/hsr_before.png' width="250"></div>
                <img src='images/hsr_after.png' width="250">
              </div>
              <script type="text/javascript">
                function hsr_start() {
                  document.getElementById('hsr_image').style.opacity = "1";
                }
                function hsr_stop() {
                  document.getElementById('hsr_image').style.opacity = "0";
                }
                hsr_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-19784-0_26">
                <papertitle><font size="5">Hierarchical Semantic Regularization of Latent Spaces in StyleGANs</font></papertitle>
              </a>
              <br>
              <font size="3">
              Tejan Karmali,
              Rishubh Parihar,
              Susmit Agrawal,
              Harsh Rangwani,
              Varun Jampani,
              Manish Singh,
              R. Venkatesh Babu
              </font>
              <br>
              <Strong>ECCV, 2022</Strong> 
              <br>
              <a href="https://sites.google.com/view/hsr-eccv22/">project page</a>
              /
              <a href="https://arxiv.org/abs/2208.03764">arXiv</a>

              <p style="text-align: justify;"> 
              Proposed a hierarchical regularizer during the training of StyleGAN models to induce smoothness properties in the W/W+ latent spaces. 
              The regularizer is implemented by guiding the intermediate features of the StyleGAN with the features from the pretrained feature extractors.
              </p>
            </td>
          </tr>		
          

          <!-- motion type Paper --> 
          <tr onmouseout="motiontype_stop()" onmouseover="motiontype_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='motiontype_image'>
                  <img src='images/motiontype_before.png' width="250"></div>
                <img src='images/motiontype_after.png' width="250">
              </div>
              <script type="text/javascript">
                function motiontype_start() {
                  document.getElementById('motiontype_image').style.opacity = "1";
                }
                function motiontype_stop() {
                  document.getElementById('motiontype_image').style.opacity = "0";
                }
                motiontype_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.01015">
                <papertitle><font size="5">Spatio-Temporal Video Representation Learning via motion type classification</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Gaurav Ramola,
              Ranajit Saha,
              Ravi Kini,
              Aniket Rege,
              Sudha Velusamy
              </font> 
              <br>
              <Strong>ICCVW - SRVU, 2021</Strong> 
              <br>
              <a href="https://arxiv.org/abs/2110.01015">arXiv</a>
              <p style="text-align: justify;"> 
                In this paper, we propose a novel approach for understanding object motions via motion type classification.
                The proposed motion type classifier predicts a motion type for the video based on the trajectories of the objects present. 
                Our classifier assigns a motion type for the given video from the following five primitive motion classes: linear, projectile, oscillatory, local and random. 
                We demonstrate that the representations learned from the motion type classification generalizes well for the challenging downstream task of video retrieval. 
                Further, we proposed a recommendation system for video playback style based on the motion type classifier predictions.
              </p>
            </td>
          </tr>		


          <!-- fabsoften Paper --> 
          <tr onmouseout="fabsoften_stop()" onmouseover="fabsoften_start()">
            <td style="padding:50px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fabsoften_image'>
                  <img src='images/fabsoften_before.png' width="200"></div>
                <img src='images/fabsoften_after.png' width="200">
              </div>
              <script type="text/javascript">
                function fabsoften_start() {
                  document.getElementById('fabsoften_image').style.opacity = "1";
                }
                function fabsoften_stop() {
                  document.getElementById('fabsoften_image').style.opacity = "0";
                }
                fabsoften_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Velusamy_FabSoften_Face_Beautification_via_Dynamic_Skin_Smoothing_Guided_Feathering_and_CVPRW_2020_paper.pdf">
                <papertitle><font size="5">FabSoften: Face Beautification via Dynamic Skin Smoothing, Guided
                  Feathering, and Texture Restoration</font></papertitle>
              </a>
              <br>
              <font size="3">
              Sudha Velusamy,
              Rishubh Parihar,
              Ravi Kini,               
              Aniket Rege
              </font>
              <br>
              <Strong>CVPRW - NTIRE, 2020</Strong>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Velusamy_FabSoften_Face_Beautification_via_Dynamic_Skin_Smoothing_Guided_Feathering_and_CVPRW_2020_paper.pdf">pdf</a>
              <p style="text-align: justify;"> 
                We propose a real-time face softening approach that smooths blemishes in the facial skin region, followed by a wavelet band manipulation to restore
                the underlying skin texture, which produces a highly appealing â€˜beautifiedâ€™ face that retains its natural appearance.
              </p>
            </td>
          </tr>		 

          <!-- makeup Paper --> 
          <tr onmouseout="makeup_stop()" onmouseover="makeup_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='makeup_image'>
                  <img src='images/makeup_before.png' width="250"></div>
                <img src='images/makeup_after.png' width="250">
              </div>
              <script type="text/javascript">
                function makeup_start() {
                  document.getElementById('makeup_image').style.opacity = "1";
                }
                function makeup_stop() {
                  document.getElementById('makeup_image').style.opacity = "0";
                }
                makeup_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3293353.3293385">
                <papertitle><font size="5">Scene Adaptive Cosmetic Makeup Transfer</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute,
              Prem Kalra
              </font>
              <br>
              <Strong>Undergrduate Thesis</Strong>
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3293353.3293385">pdf</a>

              <p style="text-align: justify;"> 
                Given a source and a target image transferring makeup from the source image to the target image.
                The transferred makeup should blend in the scene to provide natural look. To this end, we have developed
                a complete framework which firstly relights the subject image to match the illumination of the target image. 
                We have generated 3D face models from single image and used them for realistic relighting. Following that 
                layer wise decomposition is done for relit source and target image and blending is done within corresponding layers
                to transfer makeup. Finally we have additional modules in our framework to add facial accessories. 
                As we have generated 3D models of the source and target faces we were able to add accessories directly on 3D models 
                which resulted in natural looking output.
              </p>
            </td>
          </tr>		


          <!-- pixeltransformer Paper --> 
          <tr onmouseout="pixeltransformer_stop()" onmouseover="pixeltransformer_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='pixeltransformer_image'>
                  <img src='images/pixeltransformer_before.png' width="250"></div>
                <img src='images/pixeltransformer_after.png' width="250">
              </div>
              <script type="text/javascript">
                function pixeltransformer_start() {
                  document.getElementById('pixeltransformer_image').style.opacity = "1";
                }
                function pixeltransformer_stop() {
                  document.getElementById('pixeltransformer_image').style.opacity = "0";
                }
                pixeltransformer_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Image enhancement using pixel-transformer</font></papertitle>
              </a>
              <br>
              <font size="3">
              Ankit Dhiman,
              Rishubh Parihar
              </font>
              <br> 
              <p style="text-align: justify;"> 
              We empirically validate a generative model - PixelTrans- former, which infers distribution of the spatial signal given a sparse set of input samples
              ex. image from the few ob- served pixels. We tested the method under two scenarios; when sampler polls from 1.) a noisy representation and 2.) a low-frequency representation of the underlying spatial signal. Also, we evaluated the model for the different number of encoder and decoder layers. We use the Cifar10[1] dataset for all our experiments.
              </p>
            </td>
          </tr>		

          <!-- climbers Project --> 
          <tr onmouseout="climbers_stop()" onmouseover="climbers_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='climbers_image'>
                  <img src='images/climbers_before.png' width="250"></div>
                <img src='images/climbers_after.png' width="250">
              </div>
              <script type="text/javascript">
                function climbers_start() {
                  document.getElementById('climbers_image').style.opacity = "1";
                }
                function climbers_stop() {
                  document.getElementById('climbers_image').style.opacity = "0";
                }
                climbers_stop()
              </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Probabilistic creation and rendering of climbing plants</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>
              <p style="text-align: justify;"> 
              Implemented a climbing heuristic to render climbers on required objects in a scene to enhance content creation
              for computer graphics applications. Built a graph which is a minimal abstract representation of plant for production
              of leaves and branches. Traversed the nodes in graph with geometry with materials and textures that can be rendered
              </p>
            </td>
          </tr>		
           


          <!-- frog Project --> 
          <tr onmouseout="frog_stop()" onmouseover="frog_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='frog_image'>
                  <img src='images/frog_before.png' width="250"></div>
                <img src='images/frog_after.png' width="250">
              </div>
              <script type="text/javascript">
                function frog_start() {
                  document.getElementById('frog_image').style.opacity = "1";
                }
                function frog_stop() {
                  document.getElementById('frog_image').style.opacity = "0";
                }
                frog_stop()
            </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Hierarchical Modelling of 3D animatable frog and key-frame animation</font></papertitle> 
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>
              <p style="text-align: justify;"> 
              Modeled a frog to be represented as a hierarchical model with an articulated structure
              Created animation module by interpolating key frames with diffuse, specular and ambient components
              Made an interactive game with multiple frogs which run behind use controlled insects
              </p>
            </td>
          </tr>		


          <!-- raytracer Project --> 
          <tr onmouseout="raytracer_stop()" onmouseover="raytracer_start()">
            <td style="padding:15px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='raytracer_image'>
                  <img src='images/raytracer_before.png' width="250"></div>
                <img src='images/raytracer_after.png' width="250">
              </div>
              <script type="text/javascript">
                function raytracer_start() {
                  document.getElementById('raytracer_image').style.opacity = "1";
                }
                function raytracer_stop() {
                  document.getElementById('raytracer_image').style.opacity = "0";
                }
                raytracer_stop()
            </script>
            </td>
            <td style="padding:60px;width:60%;vertical-align:middle">
              <a href="None">
                <papertitle><font size="5">Recursive ray tracer for rendering simplistic scenes</font></papertitle>
              </a>
              <br>
              <font size="3">
              Rishubh Parihar,
              Aniket Dashpute
              </font>
              <br>

              <p></p> 
              <p style="text-align: justify;"> 
                Implemented recursive ray tracing to generate an image of virtually generated 3D model by tracing path of light through pixels
                Implemented global illumination model with reflection, refraction & shadows and local illumination model with diffuse, specular and ambient components
              </p>
            </td>
          </tr>		

       

          <!-- Experience both professional and academnics -->
          <br>
          <p>
          </p>
          <table style="width:100%;border:0px;border-spacing:50px;border-collapse:separate;margin-right:center;margin-left:center;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading><font size="6">Experience</font></heading>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        

          <!-- PhD --> 
          <tr onmouseout="phd_stop()" onmouseover="phd_start()" style="margin-top: -20px;">
            <td style="padding: 20px; width: 10%; vertical-align: middle; position: relative; left: 50px;">
              <div class="one">
                <div class="two" id='iisc_logo'>
                  <img src='images/iisc_logo.jpeg' width="80"> 
                </div>
              </div>
            </td>
            <td style="padding:0px; width: 100%; vertical-align: top; position: relative; left: -100px;">
              <a href="None"> 
                <papertitle><font size="4">Indian Institute of Science, Bangalore</font></papertitle>
              </a>
              <br>
              <strong>Ph.D in Engineering, Department of Computational and Data Sciences</strong>
              <br>
              <em>August 2021 - Current</em>
            </td>
          </tr>

          
        <!-- Sharechat --> 
          <tr onmouseout="sc_stop()" onmouseover="sc_start()" style="margin-top:-40px">
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='sc_logo'>
                  <img src='images/sc_logo.png' width="80"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">ShareChat</font></papertitle>
              </a>
              <br>
              <strong>Data Scientist</strong>
              <br>
              <em>October 2020 - July 2021</em> 
            </td>
          </tr>		 


          <!-- Samsung --> 
          <tr onmouseout="samsung_stop()" onmouseover="samsung_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='samsung_logo'>
                  <img src='images/samsung_logo.png' width="80"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">Samsung Reseach India Bangalore (SRIB)</font></papertitle>
              </a>
              <br>
              <strong>Computer Vision Engineer</strong> 
              <br>
              <em>June 2018 - September 2020</em>
            </td>
          </tr>		 


          <!-- Btech --> 
          <tr onmouseout="samsung_stop()" onmouseover="samsung_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:10%;vertical-align:middle;position:relative;left:50px">
              <div class="one">
                <div class="two" id='samsung_logo'>
                  <img src='images/iitd_logo.png' width="70"></div>
              </div>
            </td>
            <td style="padding:0px;width:100%;vertical-align:top;position:relative;left:-100px">
              <a href="None">
                <papertitle><font size="4">Indian Institute of Technology, Delhi</font></papertitle>
              </a>
              <br>
              <strong>Bachelors of Technology in Mathematics and Computing</strong> 
              <br>
              <em>July 2014 - May 2018</em>
            </td>
          </tr>		 


          <!-- Btech --> 
          <tr onmouseout="btech_stop()" onmouseover="btech_start()" style="margin-top:-40px"> 
            <td style="padding:20px;width:60%;vertical-align:middle;position:relative;left:50px">
            </td>
          </tr>		  


    </tr>
  </table>

  <tr>
    <td align="center">
    <p>
      This website template is taken from <a href="https://jonbarron.info/"> here </a>
    </p>
    </td>
  </tr>

</body>

</html>